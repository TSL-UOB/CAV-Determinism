\section{Methodology} \label{s:methodology}

In this section a method for determining the \textit{simulation variance} is presented along with experimental parameters that may influence it, see Fig.~\ref{method_diagram}. The method includes scenarios that exercise different actor types and functional callbacks of the game engine that may influence thread scheduling. To replicate high computational loads, and hence game loop update rates, that may be experienced in high realism simulations, resource utilisation software is used at runtime for both central and graphical processing units.

\subsection{Experimental Aims}
The aim of the experiment is to determine if the simulation is deterministic. This is achieved by monitoring actors in repeated tests and examining the deviation in path trajectories. Actors are observed in a number of different scenarios involving a mixture of vehicles and pedestrians exercising the demands outlined in Section~\ref{s:background}. The user must specify the level of variance sufficient for their application which is used as a threshold for deterministic execution. In our case study, Section~\ref{s:case-study}, a threshold of $1cm$ was chosen for our given application which reflects the scale at which repeatability of simulation execution is required. This value is sufficiently small to allow accurate \textit{assertion checking}[ref] in urban environments but a larger value may be acceptable for non-urban environments, e.g. motorway/highway. Similarly, the threshold value should not be so small as to fail with minor computational bottlenecks, e.g. $1\mu m$. 

\subsection{Design experiment}
The experiment should be a short scenario that can be easily repeated with the same initial conditions. Data logging should be used to record the actor positions at fixed time intervals throughout the simulation in order to determine the variance in actor path. 
The maximum deviation in actor path with respect to the mean for $n$-repeated tests will indicate at what dimensional scale the game engine is deterministic. For example, if 100 tests are executed and the maximum deviation in actor path is $<1cm$, then this scenario could be interpreted as being deterministic above this scale. 

Tests should be sufficiently repeated to ensure that statistical power~\cite{cohen2013statistical} reveals any outlier errors that occur with low probability. Initial testing with the Unreal Engine indicated an actor path deviation of $1\times10^{-13} cm$ for 998 out of 1000 tests but with 3 tests reporting a deviation of over {\raise.17ex\hbox{$\scriptstyle\sim$}}$10cm$. Executing 100 repeats may seem sufficient but in this case would fail to observe these events that occur with low probability, inferring a false confidence in the results.

Game engine actors can be used to simulate the AV and other vehicles and pedestrians. For the experiment, actors should follow a series of trajectory waypoints which are hard-coded for each test type. Hard-coded waypoint values ensure all actors are given the same initial conditions and any variation comes from execution of the simulator at runtime. %
% \todo{Abanoub: what is the distance between your hard-coded waypoints, are they regularly spaced? Might need to talk about interpolation code and give link to github}

% \todo{In our experiment, gross waypoints were interpolated to give a regularly spaced set of coordinates approximately $1m$ apart, and this interpolated set of waypoints were used as "target location goals" (AB: not sure what the correct terminology is here) for the pedestrian actors. %
% For the vehicles in the simulation, waypoints are generated and interpolated in the same way but execution at runtime is slightly different where a PID controller is used to generate a velocity profile and steering angle requests to reach the destination targets.}


% We use game engine actors to simulate the AVs and other agents (vehicles and pedestrians). Actors can either follow a series of trajectory waypoints or can plan a route to a further destination using some path planning and obstacle avoidance algorithms, e.g. A* search algorithm. 

 
% Resource - Realism
To simulate the demands of realistic rendering and complex physics calculations in an otherwise simple scenario, stress programs are used to artificially occupy system resources. 
% Collision callbacks
Further to this, the experiment should be designed to create collision callbacks to the physics engine by allowing actors to collide during the scenario. 
%
The user should also design the experiment to monitor and record system CPU and GPU utilisation. Additionally, if the user is interested in real-time assessment of the simulation then FPS should also be monitored and logged.
%
Where possible a fixed $dt$ should be used and any random numbers used should be seed controlled.
% \noindent When designing the experiment(s) one needs to bare in mind the following two questions: i) Is the engine deterministic? ii) If not, how does its simulation variance vary? In simulation, actors can either follow a series of trajectory way points or they get given the destination and their AI path plans to that destination. Thus, given that an engine has a high level of simulation variance, then one needs to set up an experiment that would stress the engine in order to determine how its simulation variance vary. 
% This is best done by generating collision callbacks, because that is when engines' do a lot of calculations to determine the response after the collision. Another approach, if AI is used for path planning instead of just following predefined trajectory way points, is to introduce a decision point for the AI.\\\\
It is crucial to also make sure that any randomisation factors are eliminated in the experiment.

The user should set a deviation threshold, beyond which simulation results deemed unacceptable or non-deterministic. For the majority of CAV navigation on major roads and highways a limit of $1m$ may be acceptable but in denser urban environments a value of $1cm$ may be more appropriate. 

Depending on the number of repeated tests and the average deviation reported from the experiment, a maximum rather than average may be required if the results are close to the user-specified threshold. This is to ensure that an outlier data-point is not hidden in the average of $k$-tests


\subsection{Internal settings}
There are several error and physics collision internal settings in physics engines that can be tweaked to enhance the simulation variance of the engine.

Increasing the physics time-step calculations, which is increasing the number of calculations per unit time, would improve the simulation variance since the physics sequence will be more finely defined; but on the other hand this would be more computationally expensive. However, in such applications of V\&V of CAV simulations, the computational cost should be of less concern compared to the importance of repeatability of tests.

If the experiment setup includes the usage of the physics engine's AI then altering the navigation mesh settings in the engine, like increasing the granularity of the mesh or changing the mesh type; can improve the simulation variance as a result of allowing the AI to navigate in a more well defined space. 

Disabling rendering or running in headless mode is a way of attempting to entirely decouple the rendering engine from the physics engine, which theoretically should affect positively the repeatablility of tests. 
The downside of most physics engines is that they do not provide a headless mode in the editor setup, thus this could make running in headless mode a real challenge for verification engineers.

Running in editor or deployed mode can sometimes cause differences in performance, with deployed mode being worse, mostly due to the way settings get packaged when in deployed mode.

\begin{table*}[b]
\centering
\begin{tabular}{clclcc}
\toprule
Test ID & Test description (See Figures~\ref{Test_a} and \ref{Test_b}) & Collision/Intersection & Collision Type & Look ahead distance (m) & No. of repeats \\ \midrule
1       & Two vehicles driving                   & No  & N/A & 2 & 1000 \\
2       & Two vehicles driving                   & Yes & Vehicle and Vehicle & 2 & 1000 \\
3       & Two vehicles driving and a pedestrian  & No  & N/A & 2 & 1000 \\
4       & Two vehicles driving and a pedestrian  & Yes & Vehicle and Pedestrian & 2 & 1000 \\
5       & Two pedestrians                        & No  & N/A & 2 & 1000 \\
6       & Two pedestrians                        & Yes & Pedestrian and Pedestrian & 0.4 & 1000 \\
7       & Two pedestrians                        & Yes & Pedestrian and Pedestrian & 2 & 1000 \\
8       & Two pedestrians                        & Yes & Pedestrian and Pedestrian & 20 & 1000 \\
\bottomrule
\end{tabular}
\caption{Set of experiments}
\label{TableOfExperiments}
\end{table*}

\subsection{External settings}
Running other programs in the background, like having a web browser open, or running the physics engine in the background while performing other tasks on the same machine does also have an effect; because it alters the CPU and GPU utilisation of tasks.

Trying to run stress experiments on computers by running other programs makes it difficult to control experiments since the utilisation would be inconsistent, nonetheless, there exists dedicated stress utilisation programs which provide consistent CPU and GPU stressing. Note that during running these tests computers should be left alone and not to be used for any other purposes apart from running the experiments, else the CPU + GPU stressing will lose its consistency through out a given test. 

\subsection{Running experiment}
\noindent When it comes to running the experiment itself, things that one should consider are the problem space exploration; the number of runs that should be executed to get reliable results; the frequency of logging data of actors; and possibly having a program to monitor the hardware utilisation.
% Problem exploration, there is too many variables that one can play with. do statistical analysis some.... some of them get problematic...

\subsection{Output and analysis}
Once the experiments are run, the logged data is post processed to find the variance in the logged data between the different runs. Note that bifurcation effects can cause a jump in the variance, so it is worth plotting the different logged paths in order to determine if there are any bifurcation effects.

This whole process is repeated for various internal and external settings (if needed). 
Then various plots can be created to draw the engine's simulation variance. 
Thereon, it would be up to the verification engineers to determine where they want to define the line below which the simulation variance would be acceptable, and thus know at which levels of computational utilisation they can guarantee to run repeatable experiments.   

